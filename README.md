# Sephora Product Recommendation Prediction
**Multi-Modal Deep Learning for Cosmetics Review Classification**

## Opis problemu

Projekt rozwiƒÖzuje problem **klasyfikacji binarnej** recenzji produkt√≥w kosmetycznych:
- **Klasa 1**: U≈ºytkownik poleca produkt (`is_recommended = 1`)
- **Klasa 0**: U≈ºytkownik nie poleca produktu (`is_recommended = 0`)

### Motywacja
W bran≈ºy kosmetycznej generowane sƒÖ miliony recenzji rocznie. Automatyczna klasyfikacja sentymentu pozwala na:
- SzybkƒÖ identyfikacjƒô produkt√≥w polecanych przez u≈ºytkownik√≥w
- Wsparcie decyzji zakupowych konsument√≥w
- Analizƒô trend√≥w i preferencji klient√≥w

### Wyzwania
- **Niezr√≥wnowa≈ºenie klas**: 84% pozytywnych recenzji
- **Multi-modal data**: Tekst recenzji + cechy strukturalne (rating, price)
- **Semantic ambiguity**: Pozytywny jƒôzyk ‚â† rekomendacja

---

## Dataset

**≈πr√≥d≈Ço**: [Kaggle - Sephora Products and Skincare Reviews]((https://www.kaggle.com/datasets/nadyinky/sephora-products-and-skincare-reviews?resource=download))

**Statystyki**:
- ~1,000,000 recenzji produkt√≥w kosmetycznych
- W projekcie: **20,000 pr√≥bek** (sample dla szybko≈õci)
- Podzia≈Ç: 80% train / 20% test
- Balansowanie: SMOTE (84% ‚Üí 50% klasa pozytywna)

**Cechy**:
- **Tekst**: `review_text`, `review_title`
- **Numeryczne**: `rating` (1-5), `price_usd`, `helpfulness`
- **Kategoryczne**: `primary_category`, `secondary_category`, `skin_type`

---

## Architektury modeli

### Model 1: MLP Baseline (Tabular Only)
- **Input**: 19 cech strukturalnych (rating, price, text stats, categories)
- **Architektura**: Dense(128) ‚Üí Dense(64) ‚Üí Dense(32) ‚Üí Output
- **Regularizacja**: L2, Dropout, BatchNormalization
- **Parametry**: 13,697

### Model 2: BiLSTM + Attention (Text Only)
- **Input**: 120 token√≥w (vocabulary=5000)
- **Architektura**: 
  - Embedding(128) + SpatialDropout1D
  - 2√ó Bidirectional LSTM
  - **Custom Attention Layer**
  - Multiple pooling (Attention + GlobalMax + GlobalAvg)
- **Parametry**: 820,097

### Model 3: Fusion (Multi-modal)
- **Input**: Tekst + tabular features
- **Architektura**: 
  - Text branch: BiLSTM + Attention
  - Tabular branch: Dense MLP
  - Fusion: Concatenate ‚Üí Dense layers
- **Parametry**: 821,473

### Model 1b: MLP + PCA (Bonus)
- **Input**: Features po redukcji wymiarowo≈õci (PCA)
- Zachowuje 95% wariancji z mniejszƒÖ liczbƒÖ komponent√≥w

---

## Wyniki

| Model | AUC | Accuracy | F1 | Precision | Recall | Params |
|-------|-----|----------|----|-----------| -------|--------|
| **Model 1 (MLP)** | **0.983** | **96.24%** | **0.96** | **0.96** | **0.96** | 13,697 |
| Model 2 (BiLSTM) | 0.920 | 85.36% | 0.86 | 0.85 | 0.87 | 820,097 |
| Model 3 (Fusion) | 0.964 | 94.31% | 0.94 | 0.94 | 0.95 | 821,473 |
| Model 1b (PCA) | ~0.98 | ~96% | ~0.96 | - | - | <13,697 |

### Kluczowe wnioski
**Proste modele tabelaryczne (MLP) przewy≈ºszajƒÖ z≈Ço≈ºone architektury**  
**Cechy strukturalne (rating, price) > semantyka tekstu**  
**60√ó mniej parametr√≥w, lepsze wyniki**  
**Curse of multimodality**: dodanie s≈Çabej modalno≈õci nie pomaga

---

## Instalacja i uruchomienie

### Wymagania
```bash
Python 3.8+
TensorFlow 2.x
scikit-learn
pandas
numpy
matplotlib
seaborn
kagglehub
imbalanced-learn
```

### Instalacja
```bash
# Klonuj repozytorium
git clone https://github.com/your-username/sephora-recommendation.git
cd sephora-recommendation

# Zainstaluj zale≈ºno≈õci
pip install -r requirements.txt
```

### Uruchomienie w Google Colab
1. Otw√≥rz [Google Colab](https://colab.research.google.com/)
2. Wczytaj notebook: `sephora_recommendation.ipynb`
3. Runtime ‚Üí Change runtime type ‚Üí GPU
4. Run all cells

### Uruchomienie lokalnie
```bash
python train_all_models.py
```

---

## üìÅ Struktura projektu
```
fdl-projekt/
‚îÇ
‚îú‚îÄ‚îÄ data/                          # Preprocessed data
‚îÇ   ‚îú‚îÄ‚îÄ X_text_train.npy
‚îÇ   ‚îú‚îÄ‚îÄ X_tab_train.npy
‚îÇ   ‚îî‚îÄ‚îÄ metadata.pkl
‚îÇ
‚îú‚îÄ‚îÄ models/                        # Trained models
‚îÇ   ‚îú‚îÄ‚îÄ model1_mlp_final.keras
‚îÇ   ‚îú‚îÄ‚îÄ model2_bilstm_final.keras
‚îÇ   ‚îú‚îÄ‚îÄ model3_fusion_final.keras
‚îÇ   ‚îú‚îÄ‚îÄ model1b_pca.keras
‚îÇ   ‚îú‚îÄ‚îÄ scaler.pkl
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.pkl
‚îÇ   ‚îî‚îÄ‚îÄ pca.pkl
‚îÇ
‚îú‚îÄ‚îÄ results/                       # Visualizations
‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrices_all.png
‚îÇ   ‚îú‚îÄ‚îÄ roc_curves_all.png
‚îÇ   ‚îú‚îÄ‚îÄ training_history_all.png
‚îÇ   ‚îî‚îÄ‚îÄ pca_analysis.png
‚îÇ
‚îú‚îÄ‚îÄ notebook/
‚îÇ   ‚îú‚îÄ‚îÄ sephora-reviews.ipynb      # Main notebook
‚îÇ   ‚îî‚îÄ‚îÄ sephora-reviews.py
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ Predykcja Rekomendacji Kosmetyk√≥w przy U≈ºyciu Multimodalnych Sieci Neuronowych.pdf # Article
‚îÇ                 
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## Zaawansowane techniki

### 1. Custom Attention Layer
```python
class AttentionLayer(layers.Layer):
    # Learns which words in review are important
    # Attention weights: W, b, u (trainable)
```

### 2. SMOTE Balancing
- Synthetic Minority Over-sampling Technique
- Balansuje dataset 84% ‚Üí 50%

### 3. Multiple Pooling
- Attention pooling (learned)
- GlobalMaxPooling (max signal)
- GlobalAveragePooling (average signal)

### 4. PCA Dimensionality Reduction
- Redukcja z 19 ‚Üí ~8 features (95% variance)
- Zachowuje wydajno≈õƒá modelu

### 5. Learning Rate Scheduling
- ReduceLROnPlateau: automatyczne zmniejszanie LR
- AdamW optimizer: Adam + weight decay

---

## Wizualizacje

### Confusion Matrix
![Confusion Matrix](results/confusion_matrices_all.png)

### ROC Curves
![ROC Curves](results/roc_curves_all.png)

### Training History
![Training History](results/training_history_all.png)

### PCA Analysis
![PCA](results/pca_analysis.png)

---

## Artyku≈Ç naukowy

Pe≈Çny artyku≈Ç dostƒôpny w pliku: [`Predykcja Rekomendacji Kosmetyk√≥w przy U≈ºyciu Multimodalnych Sieci Neuronowych.pdf`](Predykcja Rekomendacji Kosmetyk√≥w przy U≈ºyciu Multimodalnych Sieci Neuronowych.pdf)

**Abstract**:
> Artyku≈Ç przedstawia por√≥wnanie trzech architektur sieci neuronowych do predykcji rekomendacji produkt√≥w kosmetycznych. Model MLP osiƒÖgnƒÖ≈Ç najlepsze wyniki (96.24% accuracy, AUC=0.983) przy najmniejszej z≈Ço≈ºono≈õci, przewy≈ºszajƒÖc model multimodalny o 1.93pp.

---

## Autorzy

- **Natalia ≈ÅƒÖczkowska** - *Polsko Japo≈Ñska Akademia Technik Komputerowych*

---

## Bibliografia

[1] Gibson Nkhata et al. "Fine-tuning BERT with Bidirectional LSTM". 2025.  
[2] Md Abrar Jahin et al. "A hybrid transformer and attention based RNN". 2024.  
[3] Mahammed Kamruzzaman et al. "Efficient Sentiment Analysis". 2023.

---

## Przysz≈Çe prace

- [ ] Pre-trained embeddings (BERT)
- [ ] Deployment jako REST API
- [ ] Multi-class classification (rating 1-5)
- [ ] Cross-domain testing
- [ ] SHAP feature importance
- [ ] Ensemble models

---
---

‚≠ê **Star this repo** if you find it helpful!
